{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "import numpy\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hist.csv')\n",
    "engine101 = pd.read_csv('Engine101.csv')\n",
    "engine102 = pd.read_csv('Engine102.csv')\n",
    "engine103 = pd.read_csv('Engine103.csv')\n",
    "engine104 = pd.read_csv('Engine104.csv')\n",
    "engine124 = pd.read_csv('Engine124.csv')\n",
    "engine125 = pd.read_csv('Engine125.csv')\n",
    "engine134 = pd.read_csv('Engine134.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine134.loc[:,'unit number'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine103.loc[:,'unit number'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "#Preparing the engine data for predicting RUL\n",
    "def prepare_engine(engine, scaler, pca):\n",
    "    \n",
    "    #Removing unit number and time in cycles column\n",
    "    engine = engine.iloc[:,2:len(engine.columns)]\n",
    "    engine = engine.values\n",
    "    \n",
    "    #Scaling using trained scaler\n",
    "    engine = engine.reshape(engine.shape[0], engine.shape[1])\n",
    "    engine = scaler.transform(engine)\n",
    "    \n",
    "    #Data compression using PCA\n",
    "    engine = pca.transform(engine)\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assigning the same prediction variable RUL to each engine \n",
    "unit_2RUL = data.loc[:,['unit number', 'RUL']].groupby('unit number').count().to_dict()['RUL']\n",
    "data.loc[:,'RUL_correct'] = data.loc[:,'unit number']\n",
    "data.replace({\"RUL_correct\":unit_2RUL}, inplace = True)\n",
    "data.drop('RUL', axis = 1, inplace= True)\n",
    "data.rename(columns= {'RUL_correct':'RUL'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting training and test data (last 20 engines)\n",
    "def get_test(df):\n",
    "    if(df['unit number'].values[0]>80):\n",
    "        return df\n",
    "\n",
    "def get_train(df):\n",
    "    if(df['unit number'].values[0]<=80):\n",
    "        return df\n",
    "        \n",
    "test = data.groupby('unit number').apply(get_test).reset_index(drop = True).dropna(axis= 0)\n",
    "train = data.groupby('unit number').apply(get_train).reset_index(drop = True).dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing unit number and time in cycles column\n",
    "#For train\n",
    "train_series_x = train.iloc[:,2:len(data.columns)-1]\n",
    "train_series_y = train.iloc[:,-1]\n",
    "#For test\n",
    "test_series_x = test.iloc[:,2:len(data.columns)-1]\n",
    "test_series_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_test_x = test_series_x.values\n",
    "raw_train_x = train_series_x.values\n",
    "\n",
    "raw_test_y = test_series_y.values\n",
    "raw_train_y = train_series_y.values\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(raw_train_x, raw_test_x)\n",
    "\n",
    "#Renaming\n",
    "train_x = train_scaled\n",
    "test_x = test_scaled\n",
    "train_y = raw_train_y\n",
    "test_y = raw_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing(Data Compression)\n",
    "pca = PCA()\n",
    "pca.fit(train_x)\n",
    "VarianceRatio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Retained Variance: 0.9937482418231226\n",
      "Number of principal components 14\n"
     ]
    }
   ],
   "source": [
    "#Finding number of principal components\n",
    "#Retaining 99% of total variance \n",
    "TotVar = 0 \n",
    "for idx, Var in enumerate(VarianceRatio):\n",
    "    TotVar += Var \n",
    "    if(TotVar>=0.99): \n",
    "        break \n",
    "print('Total Retained Variance: {}'.format(TotVar)) \n",
    "print('Number of principal components {}'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Again fitting pca for 14 principal components\n",
    "pcaRed = PCA(n_components = 14,whiten= True)\n",
    "pcaRed.fit(train_x)\n",
    "#Compressing training and testing data using fitted data\n",
    "train_x = pcaRed.transform(train_x)\n",
    "test_x = pcaRed.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenating train and test for grid search\n",
    "X = np.concatenate((train_x, test_x), axis = 0)\n",
    "y = np.concatenate((train_y, test_y), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 50, 'gamma': 1}\n",
      "Best test cross validation R2 score 0.9999957746530638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Grid search\n",
    "clf = SVR(kernel = 'rbf')\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 20, 50,100, 500], 'gamma': [0.01, 0.1, 1, 10, 50, 100]}\n",
    "gs = GridSearchCV(clf, parameters)\n",
    "gs.fit(X, y)\n",
    "best_params = gs.best_params_\n",
    "print(\"Best Parameters: {}\".format(gs.best_params_))\n",
    "print(\"Best test cross validation R2 score {}\".format(np.max(gs.cv_results_['mean_train_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=50, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the regression model with best parameters\n",
    "clf = SVR(kernel = 'rbf', C = best_params['C'], gamma = best_params['gamma'])\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preparing test engine data\n",
    "engine101 = prepare_engine(engine101, scaler, pcaRed)\n",
    "engine102 = prepare_engine(engine102, scaler, pcaRed)\n",
    "engine103 = prepare_engine(engine103, scaler, pcaRed)\n",
    "engine104 = prepare_engine(engine104, scaler, pcaRed)\n",
    "engine124 = prepare_engine(engine124, scaler, pcaRed)\n",
    "engine125 = prepare_engine(engine125, scaler, pcaRed)\n",
    "engine134 = prepare_engine(engine134, scaler, pcaRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted RUL for engine 101: 180\n",
      "Predicted RUL for engine 102: 159\n",
      "Predicted RUL for engine 103: 84\n",
      "Predicted RUL for engine 104: 102\n",
      "Predicted RUL for engine 124: 26\n",
      "Predicted RUL for engine 125: 162\n",
      "Predicted RUL for engine 134: -94\n"
     ]
    }
   ],
   "source": [
    "#Predicting the RUL for new engines\n",
    "e1 = clf.predict(engine101)\n",
    "e2 = clf.predict(engine102)\n",
    "e3 = clf.predict(engine103)\n",
    "e4 = clf.predict(engine104)\n",
    "e24 = clf.predict(engine124)\n",
    "e25 = clf.predict(engine125)\n",
    "e34 = clf.predict(engine134)\n",
    "print(\"Predicted RUL for engine 101: {}\".format(int(np.mean(e1) - len(e1))))\n",
    "print(\"Predicted RUL for engine 102: {}\".format(int(np.mean(e2) - len(e2))))\n",
    "print(\"Predicted RUL for engine 103: {}\".format(int(np.mean(e3) - len(e3))))\n",
    "print(\"Predicted RUL for engine 104: {}\".format(int(np.mean(e4) - len(e4))))\n",
    "print(\"Predicted RUL for engine 124: {}\".format(int(np.mean(e24) - len(e24))))\n",
    "print(\"Predicted RUL for engine 125: {}\".format(int(np.mean(e25) - len(e25))))\n",
    "print(\"Predicted RUL for engine 134: {}\".format(int(np.mean(e34) - len(e34))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
